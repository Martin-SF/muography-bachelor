{"cells":[{"cell_type":"code","execution_count":1,"source":["# print(os.getcwd())\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import os, sys\n","from uncertainties import ufloat\n","# from numba import jit, njit, vectorize, prange\n","from importlib import reload\n","import py_library.my_plots_library as plib\n","import py_library.stopwatch as stopwatch\n","import py_library.simulate_lib as slib\n","import proposal as pp\n","from distributed import Client\n","from dask.distributed import performance_report\n","import dask.dataframe as dd\n","import dask.bag as db\n","\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.rcParams['font.size'] = 12\n","plt.rcParams['lines.linewidth'] = 2\n","plt.rcParams['axes.labelsize'] = 14\n","plt.rcParams.update({'figure.dpi':70})\n","# os.chdir(os.path.dirname(__file__))  # wichtig wenn nicht über ipython ausgeführt\n","client = Client(\"localhost:8786\") # phobos\n","FLOAT_TYPE = np.float64\n","{\n","'''\n","1e7\n","workers:\n","2400 KilledWorker: ('finalize-6d57127f026613e3fce3aa1731d26349', <WorkerState 'tcp://127.0.0.1:43417', status: closed, memory: 0, processing: 1>) \n","240 \n","24 2 worker sind abgeschmiert aber es lief durch \n","'''\n","}\n","show_plots = True\n","print_results = False\n","silent = True\n","# hdf_folder = 'data_hdf/'\n","hdf_folder = '/scratch/mschoenfeld/data_hdf/'\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e7_min2e2_max2e5.hdf\"\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min4e2_max2e5.hdf\"\n","\n","file_name = \"EcoMug_gaisser_30deg_3e7_min5e2_max2e5.hdf\" # 1517.6 s\n","file_name = \"EcoMug_gaisser_30deg_1e7_min5e2_max2e5.hdf\" \n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e5_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf\"\n","vcut = ''\n","multiple_scattering = 'HighlandIntegral'\n","multiple_scattering = 'Moliere'\n","vcut = 1\n","vcut = 0.01\n","vcut = 0.0001\n","vcut = 0.001\n","worker_number = 23\n","print(f'{file_name} | worker_number = {worker_number}')\n","\n","# %\n","######################################################################\n","######################################################################\n","t1 = stopwatch.stopwatch(\n","    title='full proposal init and simulation parallized with dask',\n","    time_unit='s')\n","t1.task('initialize proposal, making interpol tables')\n","\n","import d_pp_lib as proper\n","client.upload_file('d_pp_lib.py')\n","reload(proper)\n","pp_config = f'v{vcut}_{multiple_scattering}'\n","print(f'PROPOSAL config = {proper.config} | ppconfig = {pp_config}')\n","reload(stopwatch)\n","reload(plib)\n","\n","STATISTICS = len(pd.read_hdf(\n","    hdf_folder+file_name, key=f'main', columns=['charge']))\n","chunksize = round((STATISTICS/worker_number))+1\n","\n","meta={\n","    'hit_detector': bool, \n","    'distances_f_raw': FLOAT_TYPE, \n","    'energies_f_raw': FLOAT_TYPE, \n","    'energies_i_raw': FLOAT_TYPE, \n","    'point1x_raw': FLOAT_TYPE, \n","    'point1y_raw': FLOAT_TYPE, \n","    'point1z_raw': FLOAT_TYPE, \n","    'point2x_raw': FLOAT_TYPE,\n","    'point2y_raw': FLOAT_TYPE,\n","    'point2z_raw': FLOAT_TYPE\n","}\n","\n","t1.task('dask compute', True)\n","''' \n","future = client.submit(func, big_data)    # bad\n","\n","    big_future = client.scatter(big_data)     # good\n","    future = client.submit(func, big_future)  # good\n","    # own approach\n","    ddf = client.scatter(ddf)\n","    dfb = ddf.result().to_bag()\n","    # dfb = client.map(proper.pp_propagate, db.from_delayed(dfb) ) #27s\n","    # dfb = client.map(proper.pp_propagate, dfb) #27s\n","'''\n","with performance_report(filename=\"dask-report.html\"):\n","    ddf = dd.read_hdf(hdf_folder+file_name, key='main',\n","                    columns=['energy', 'theta', 'phi', 'charge'], chunksize=chunksize)\n","    dfb = ddf.to_bag()\n","\n","    dfb = dfb.map(proper.pp_propagate) #27s\n","    ddfr = dfb.to_dataframe(meta=meta)\n","    # ddfr.to_hdf(hdf_folder+'results_raw_'+file_name, key=f'main', format='table')\n","    results = client.compute(ddfr, pure=False).result()\n","\n","t1.stop(silent)\n","# %\n","t2 = stopwatch.stopwatch(title='processing of results')\n","t2.task('nachbereitung')\n","######################################################################\n","######################################################################\n","\n","\n","hit_detector = np.array(results['hit_detector'], dtype=bool)\n","distances_f_raw = np.array(results['distances_f_raw'], dtype=FLOAT_TYPE)\n","energies_f_raw = np.array(results['energies_f_raw'], dtype=FLOAT_TYPE)\n","energies_i_raw = np.array(results['energies_i_raw'], dtype=FLOAT_TYPE)\n","point1x_raw = np.array(results['point1x_raw'], dtype=FLOAT_TYPE)\n","point1y_raw = np.array(results['point1y_raw'], dtype=FLOAT_TYPE)\n","point1z_raw = np.array(results['point1z_raw'], dtype=FLOAT_TYPE)\n","point2x_raw = np.array(results['point2x_raw'], dtype=FLOAT_TYPE)\n","point2y_raw = np.array(results['point2y_raw'], dtype=FLOAT_TYPE)\n","point2z_raw = np.array(results['point2z_raw'], dtype=FLOAT_TYPE)\n","\n","counter = int(sum(hit_detector))  #len von allen die True sind\n","energies_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","energies_i = np.zeros(counter, dtype=FLOAT_TYPE)\n","distances_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","start_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","end_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","start_end_points = np.zeros(shape=(counter*2, 3), dtype=FLOAT_TYPE)\n","\n","t2.task('1')\n","i2 = 0\n","for i in range(STATISTICS):\n","    if hit_detector[i] == True:\n","        energies_f[i2] = energies_f_raw[i]\n","        energies_i[i2] = energies_i_raw[i]\n","        distances_f[i2] = distances_f_raw[i]\n","\n","        start_points[i2] = np.array([point1x_raw[i], point1y_raw[i], point1z_raw[i]])\n","        end_points[i2] = np.array([point2x_raw[i], point2y_raw[i], point2z_raw[i]])\n","\n","        start_end_points[i2*2] = start_points[i2]\n","        start_end_points[i2*2+1] = end_points[i2]\n","        i2 += 1\n","\n","t2.task('2')\n","df = pd.DataFrame()\n","df['energies_f'] = energies_f\n","df['energies_i'] = energies_i\n","df['distances'] = distances_f\n","df['point1x'] = start_points[:, 0]\n","df['point1y'] = start_points[:, 1]\n","df['point1z'] = start_points[:, 2]\n","df['point2x'] = end_points[:, 0]\n","df['point2y'] = end_points[:, 1]\n","df['point2z'] = end_points[:, 2]\n","\n","t2.task('3')\n","t2.task('write to HDF file')\n","file_name_results = f'results_{pp_config}_{file_name}'\n","df.to_hdf(hdf_folder+file_name_results, key=f'main', format='table')\n","counter = ufloat(counter, counter*0.01)"],"outputs":[{"output_type":"stream","name":"stdout","text":["EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf | worker_number = 23\n","PROPOSAL config = sandstein_det_genauer_Wasser.json | ppconfig = v0.001_Moliere\n","dask compute took  4016.2 s\n"]}],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["counter_u = ufloat(counter, 1/np.sqrt(counter))\n","t2.task('4')\n","s1 = f'{counter_u:.1f} of {STATISTICS:.0e} ({counter_u/STATISTICS*100:.4}%) detector hits'\n","# s1 = f'{counter} of {STATISTICS:.0e} %) detector hits'\n","s2 = f'min(E_i) at detector = {min(energies_i)/1000:.1f} GeV'\n","print(f'{s1} | {s2}')\n","\n","t2.stop(silent)"],"outputs":[{"output_type":"stream","name":"stdout","text":["774878.0+/-0.0 of 1e+07 (7.749+/-0.000%) detector hits | min(E_i) at detector = 869.4 GeV\n"]}],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["# print(os.getcwd())\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import os, sys\n","from uncertainties import ufloat\n","# from numba import jit, njit, vectorize, prange\n","from importlib import reload\n","import py_library.my_plots_library as plib\n","import py_library.stopwatch as stopwatch\n","import py_library.simulate_lib as slib\n","import proposal as pp\n","from distributed import Client\n","from dask.distributed import performance_report\n","import dask.dataframe as dd\n","import dask.bag as db\n","\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.rcParams['font.size'] = 12\n","plt.rcParams['lines.linewidth'] = 2\n","plt.rcParams['axes.labelsize'] = 14\n","plt.rcParams.update({'figure.dpi':70})\n","# os.chdir(os.path.dirname(__file__))  # wichtig wenn nicht über ipython ausgeführt\n","client = Client(\"localhost:8786\") # phobos\n","FLOAT_TYPE = np.float64\n","{\n","'''\n","1e7\n","workers:\n","2400 KilledWorker: ('finalize-6d57127f026613e3fce3aa1731d26349', <WorkerState 'tcp://127.0.0.1:43417', status: closed, memory: 0, processing: 1>) \n","240 \n","24 2 worker sind abgeschmiert aber es lief durch \n","'''\n","}\n","show_plots = True\n","print_results = False\n","silent = True\n","# hdf_folder = 'data_hdf/'\n","hdf_folder = '/scratch/mschoenfeld/data_hdf/'\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e7_min2e2_max2e5.hdf\"\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min4e2_max2e5.hdf\"\n","\n","file_name = \"EcoMug_gaisser_30deg_3e7_min5e2_max2e5.hdf\" # 1517.6 s\n","file_name = \"EcoMug_gaisser_30deg_1e7_min5e2_max2e5.hdf\" \n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e5_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf\"\n","vcut = ''\n","multiple_scattering = 'HighlandIntegral'\n","multiple_scattering = 'Moliere'\n","vcut = 1\n","vcut = 0.01\n","vcut = 0.001\n","vcut = 0.0001\n","vcut = 0.0008\n","worker_number = 23\n","print(f'{file_name} | worker_number = {worker_number}')\n","\n","# %\n","######################################################################\n","######################################################################\n","t1 = stopwatch.stopwatch(\n","    title='full proposal init and simulation parallized with dask',\n","    time_unit='s')\n","t1.task('initialize proposal, making interpol tables')\n","\n","import d_pp_lib as proper\n","client.upload_file('d_pp_lib.py')\n","reload(proper)\n","pp_config = f'v{vcut}_{multiple_scattering}'\n","print(f'PROPOSAL config = {proper.config} | ppconfig = {pp_config}')\n","reload(stopwatch)\n","reload(plib)\n","\n","STATISTICS = len(pd.read_hdf(\n","    hdf_folder+file_name, key=f'main', columns=['charge']))\n","chunksize = round((STATISTICS/worker_number))+1\n","\n","meta={\n","    'hit_detector': bool, \n","    'distances_f_raw': FLOAT_TYPE, \n","    'energies_f_raw': FLOAT_TYPE, \n","    'energies_i_raw': FLOAT_TYPE, \n","    'point1x_raw': FLOAT_TYPE, \n","    'point1y_raw': FLOAT_TYPE, \n","    'point1z_raw': FLOAT_TYPE, \n","    'point2x_raw': FLOAT_TYPE,\n","    'point2y_raw': FLOAT_TYPE,\n","    'point2z_raw': FLOAT_TYPE\n","}\n","\n","t1.task('dask tasks', True)\n","''' \n","future = client.submit(func, big_data)    # bad\n","\n","    big_future = client.scatter(big_data)     # good\n","    future = client.submit(func, big_future)  # good\n","    # own approach\n","    ddf = client.scatter(ddf)\n","    dfb = ddf.result().to_bag()\n","    # dfb = client.map(proper.pp_propagate, db.from_delayed(dfb) ) #27s\n","    # dfb = client.map(proper.pp_propagate, dfb) #27s\n","'''\n","with performance_report(filename=\"dask-report.html\"):\n","    ddf = dd.read_hdf(hdf_folder+file_name, key='main',\n","                    columns=['energy', 'theta', 'phi', 'charge'], chunksize=chunksize)\n","    dfb = ddf.to_bag()\n","\n","    dfb = dfb.map(proper.pp_propagate) #27s\n","    ddfr = dfb.to_dataframe(meta=meta)\n","    # ddfr.to_hdf(hdf_folder+'results_raw_'+file_name, key=f'main', format='table')\n","    results = client.compute(ddfr, pure=False).result()\n","\n","t1.stop(silent)\n","# %\n","t2 = stopwatch.stopwatch(title='processing of results')\n","t2.task('nachbereitung')\n","######################################################################\n","######################################################################\n","\n","\n","hit_detector = np.array(results['hit_detector'], dtype=bool)\n","distances_f_raw = np.array(results['distances_f_raw'], dtype=FLOAT_TYPE)\n","energies_f_raw = np.array(results['energies_f_raw'], dtype=FLOAT_TYPE)\n","energies_i_raw = np.array(results['energies_i_raw'], dtype=FLOAT_TYPE)\n","point1x_raw = np.array(results['point1x_raw'], dtype=FLOAT_TYPE)\n","point1y_raw = np.array(results['point1y_raw'], dtype=FLOAT_TYPE)\n","point1z_raw = np.array(results['point1z_raw'], dtype=FLOAT_TYPE)\n","point2x_raw = np.array(results['point2x_raw'], dtype=FLOAT_TYPE)\n","point2y_raw = np.array(results['point2y_raw'], dtype=FLOAT_TYPE)\n","point2z_raw = np.array(results['point2z_raw'], dtype=FLOAT_TYPE)\n","\n","counter = int(sum(hit_detector))  #len von allen die True sind\n","energies_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","energies_i = np.zeros(counter, dtype=FLOAT_TYPE)\n","distances_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","start_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","end_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","start_end_points = np.zeros(shape=(counter*2, 3), dtype=FLOAT_TYPE)\n","\n","t2.task('1')\n","i2 = 0\n","for i in range(STATISTICS):\n","    if hit_detector[i] == True:\n","        energies_f[i2] = energies_f_raw[i]\n","        energies_i[i2] = energies_i_raw[i]\n","        distances_f[i2] = distances_f_raw[i]\n","\n","        start_points[i2] = np.array([point1x_raw[i], point1y_raw[i], point1z_raw[i]])\n","        end_points[i2] = np.array([point2x_raw[i], point2y_raw[i], point2z_raw[i]])\n","\n","        start_end_points[i2*2] = start_points[i2]\n","        start_end_points[i2*2+1] = end_points[i2]\n","        i2 += 1\n","\n","t2.task('2')\n","df = pd.DataFrame()\n","df['energies_f'] = energies_f\n","df['energies_i'] = energies_i\n","df['distances'] = distances_f\n","df['point1x'] = start_points[:, 0]\n","df['point1y'] = start_points[:, 1]\n","df['point1z'] = start_points[:, 2]\n","df['point2x'] = end_points[:, 0]\n","df['point2y'] = end_points[:, 1]\n","df['point2z'] = end_points[:, 2]\n","\n","t2.task('3')\n","t2.task('write to HDF file')\n","file_name_results = f'results_{pp_config}_{file_name}'\n","df.to_hdf(hdf_folder+file_name_results, key=f'main', format='table')\n","counter_u = ufloat(counter, 1/np.sqrt(counter))\n","t2.task('4')\n","s1 = f'{counter_u:.1f} of {STATISTICS:.0e} ({counter_u/STATISTICS*100:.4}%) detector hits'\n","# s1 = f'{counter} of {STATISTICS:.0e} %) detector hits'\n","s2 = f'min(E_i) at detector = {min(energies_i)/1000:.1f} GeV'\n","print(f'{s1} | {s2}')\n","\n","t2.stop(silent)"],"outputs":[{"output_type":"stream","name":"stdout","text":["EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf | worker_number = 23\n","PROPOSAL config = sandstein_det_genauer_Wasser.json | ppconfig = v0.0008_Moliere\n","dask tasks took    15.1 s\n","766.0+/-0.0 of 1e+04 (7.660+/-0.000%) detector hits | min(E_i) at detector = 1018.2 GeV\n"]}],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["# print(os.getcwd())\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import os, sys\n","from uncertainties import ufloat\n","# from numba import jit, njit, vectorize, prange\n","from importlib import reload\n","import py_library.my_plots_library as plib\n","import py_library.stopwatch as stopwatch\n","import py_library.simulate_lib as slib\n","import proposal as pp\n","from distributed import Client\n","from dask.distributed import performance_report\n","import dask.dataframe as dd\n","import dask.bag as db\n","\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.rcParams['font.size'] = 12\n","plt.rcParams['lines.linewidth'] = 2\n","plt.rcParams['axes.labelsize'] = 14\n","plt.rcParams.update({'figure.dpi':70})\n","# os.chdir(os.path.dirname(__file__))  # wichtig wenn nicht über ipython ausgeführt\n","client = Client(\"localhost:8786\") # phobos\n","FLOAT_TYPE = np.float64\n","{\n","'''\n","1e7\n","workers:\n","2400 KilledWorker: ('finalize-6d57127f026613e3fce3aa1731d26349', <WorkerState 'tcp://127.0.0.1:43417', status: closed, memory: 0, processing: 1>) \n","240 \n","24 2 worker sind abgeschmiert aber es lief durch \n","'''\n","}\n","show_plots = True\n","print_results = False\n","silent = True\n","# hdf_folder = 'data_hdf/'\n","hdf_folder = '/scratch/mschoenfeld/data_hdf/'\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e7_min2e2_max2e5.hdf\"\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min4e2_max2e5.hdf\"\n","\n","file_name = \"EcoMug_gaisser_30deg_3e7_min5e2_max2e5.hdf\" # 1517.6 s\n","file_name = \"EcoMug_gaisser_30deg_1e7_min5e2_max2e5.hdf\" \n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e5_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf\"\n","vcut = ''\n","multiple_scattering = 'HighlandIntegral'\n","multiple_scattering = 'Moliere'\n","vcut = 1\n","vcut = 0.01\n","vcut = 0.001\n","vcut = 0.0001\n","vcut = 0.0007\n","worker_number = 23\n","print(f'{file_name} | worker_number = {worker_number}')\n","\n","# %\n","######################################################################\n","######################################################################\n","t1 = stopwatch.stopwatch(\n","    title='full proposal init and simulation parallized with dask',\n","    time_unit='s')\n","t1.task('initialize proposal, making interpol tables')\n","\n","import d_pp_lib as proper\n","client.upload_file('d_pp_lib.py')\n","reload(proper)\n","pp_config = f'v{vcut}_{multiple_scattering}'\n","print(f'PROPOSAL config = {proper.config} | ppconfig = {pp_config}')\n","reload(stopwatch)\n","reload(plib)\n","\n","STATISTICS = len(pd.read_hdf(\n","    hdf_folder+file_name, key=f'main', columns=['charge']))\n","chunksize = round((STATISTICS/worker_number))+1\n","\n","meta={\n","    'hit_detector': bool, \n","    'distances_f_raw': FLOAT_TYPE, \n","    'energies_f_raw': FLOAT_TYPE, \n","    'energies_i_raw': FLOAT_TYPE, \n","    'point1x_raw': FLOAT_TYPE, \n","    'point1y_raw': FLOAT_TYPE, \n","    'point1z_raw': FLOAT_TYPE, \n","    'point2x_raw': FLOAT_TYPE,\n","    'point2y_raw': FLOAT_TYPE,\n","    'point2z_raw': FLOAT_TYPE\n","}\n","\n","t1.task('dask tasks', True)\n","''' \n","future = client.submit(func, big_data)    # bad\n","\n","    big_future = client.scatter(big_data)     # good\n","    future = client.submit(func, big_future)  # good\n","    # own approach\n","    ddf = client.scatter(ddf)\n","    dfb = ddf.result().to_bag()\n","    # dfb = client.map(proper.pp_propagate, db.from_delayed(dfb) ) #27s\n","    # dfb = client.map(proper.pp_propagate, dfb) #27s\n","'''\n","with performance_report(filename=\"dask-report.html\"):\n","    ddf = dd.read_hdf(hdf_folder+file_name, key='main',\n","                    columns=['energy', 'theta', 'phi', 'charge'], chunksize=chunksize)\n","    dfb = ddf.to_bag()\n","\n","    dfb = dfb.map(proper.pp_propagate) #27s\n","    ddfr = dfb.to_dataframe(meta=meta)\n","    # ddfr.to_hdf(hdf_folder+'results_raw_'+file_name, key=f'main', format='table')\n","    results = client.compute(ddfr, pure=False).result()\n","\n","t1.stop(silent)\n","# %\n","t2 = stopwatch.stopwatch(title='processing of results')\n","t2.task('nachbereitung')\n","######################################################################\n","######################################################################\n","\n","\n","hit_detector = np.array(results['hit_detector'], dtype=bool)\n","distances_f_raw = np.array(results['distances_f_raw'], dtype=FLOAT_TYPE)\n","energies_f_raw = np.array(results['energies_f_raw'], dtype=FLOAT_TYPE)\n","energies_i_raw = np.array(results['energies_i_raw'], dtype=FLOAT_TYPE)\n","point1x_raw = np.array(results['point1x_raw'], dtype=FLOAT_TYPE)\n","point1y_raw = np.array(results['point1y_raw'], dtype=FLOAT_TYPE)\n","point1z_raw = np.array(results['point1z_raw'], dtype=FLOAT_TYPE)\n","point2x_raw = np.array(results['point2x_raw'], dtype=FLOAT_TYPE)\n","point2y_raw = np.array(results['point2y_raw'], dtype=FLOAT_TYPE)\n","point2z_raw = np.array(results['point2z_raw'], dtype=FLOAT_TYPE)\n","\n","counter = int(sum(hit_detector))  #len von allen die True sind\n","energies_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","energies_i = np.zeros(counter, dtype=FLOAT_TYPE)\n","distances_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","start_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","end_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","start_end_points = np.zeros(shape=(counter*2, 3), dtype=FLOAT_TYPE)\n","\n","t2.task('1')\n","i2 = 0\n","for i in range(STATISTICS):\n","    if hit_detector[i] == True:\n","        energies_f[i2] = energies_f_raw[i]\n","        energies_i[i2] = energies_i_raw[i]\n","        distances_f[i2] = distances_f_raw[i]\n","\n","        start_points[i2] = np.array([point1x_raw[i], point1y_raw[i], point1z_raw[i]])\n","        end_points[i2] = np.array([point2x_raw[i], point2y_raw[i], point2z_raw[i]])\n","\n","        start_end_points[i2*2] = start_points[i2]\n","        start_end_points[i2*2+1] = end_points[i2]\n","        i2 += 1\n","\n","t2.task('2')\n","df = pd.DataFrame()\n","df['energies_f'] = energies_f\n","df['energies_i'] = energies_i\n","df['distances'] = distances_f\n","df['point1x'] = start_points[:, 0]\n","df['point1y'] = start_points[:, 1]\n","df['point1z'] = start_points[:, 2]\n","df['point2x'] = end_points[:, 0]\n","df['point2y'] = end_points[:, 1]\n","df['point2z'] = end_points[:, 2]\n","\n","t2.task('3')\n","t2.task('write to HDF file')\n","file_name_results = f'results_{pp_config}_{file_name}'\n","df.to_hdf(hdf_folder+file_name_results, key=f'main', format='table')\n","counter_u = ufloat(counter, 1/np.sqrt(counter))\n","t2.task('4')\n","s1 = f'{counter_u:.1f} of {STATISTICS:.0e} ({counter_u/STATISTICS*100:.4}%) detector hits'\n","# s1 = f'{counter} of {STATISTICS:.0e} %) detector hits'\n","s2 = f'min(E_i) at detector = {min(energies_i)/1000:.1f} GeV'\n","print(f'{s1} | {s2}')\n","\n","t2.stop(silent)"],"outputs":[{"output_type":"stream","name":"stdout","text":["EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf | worker_number = 23\n","PROPOSAL config = sandstein_det_genauer_Wasser.json | ppconfig = v0.0007_Moliere\n","dask tasks took    17.3 s\n","799.0+/-0.0 of 1e+04 (7.990+/-0.000%) detector hits | min(E_i) at detector = 1030.3 GeV\n"]}],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# print(os.getcwd())\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import os, sys\n","from uncertainties import ufloat\n","# from numba import jit, njit, vectorize, prange\n","from importlib import reload\n","import py_library.my_plots_library as plib\n","import py_library.stopwatch as stopwatch\n","import py_library.simulate_lib as slib\n","import proposal as pp\n","from distributed import Client\n","from dask.distributed import performance_report\n","import dask.dataframe as dd\n","import dask.bag as db\n","\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.rcParams['font.size'] = 12\n","plt.rcParams['lines.linewidth'] = 2\n","plt.rcParams['axes.labelsize'] = 14\n","plt.rcParams.update({'figure.dpi':70})\n","# os.chdir(os.path.dirname(__file__))  # wichtig wenn nicht über ipython ausgeführt\n","client = Client(\"localhost:8786\") # phobos\n","FLOAT_TYPE = np.float64\n","{\n","'''\n","1e7\n","workers:\n","2400 KilledWorker: ('finalize-6d57127f026613e3fce3aa1731d26349', <WorkerState 'tcp://127.0.0.1:43417', status: closed, memory: 0, processing: 1>) \n","240 \n","24 2 worker sind abgeschmiert aber es lief durch \n","'''\n","}\n","show_plots = True\n","print_results = False\n","silent = True\n","# hdf_folder = 'data_hdf/'\n","hdf_folder = '/scratch/mschoenfeld/data_hdf/'\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e7_min2e2_max2e5.hdf\"\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min4e2_max2e5.hdf\"\n","\n","file_name = \"EcoMug_gaisser_30deg_3e7_min5e2_max2e5.hdf\" # 1517.6 s\n","file_name = \"EcoMug_gaisser_30deg_1e7_min5e2_max2e5.hdf\" \n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e5_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf\"\n","vcut = ''\n","multiple_scattering = 'HighlandIntegral'\n","multiple_scattering = 'Moliere'\n","vcut = 1\n","vcut = 0.01\n","vcut = 0.0001\n","vcut = 0.0008\n","worker_number = 23\n","print(f'{file_name} | worker_number = {worker_number}')\n","\n","# %\n","######################################################################\n","######################################################################\n","t1 = stopwatch.stopwatch(\n","    title='full proposal init and simulation parallized with dask',\n","    time_unit='s')\n","t1.task('initialize proposal, making interpol tables')\n","\n","import d_pp_lib as proper\n","client.upload_file('d_pp_lib.py')\n","reload(proper)\n","pp_config = f'v{vcut}_{multiple_scattering}'\n","print(f'PROPOSAL config = {proper.config} | ppconfig = {pp_config}')\n","reload(stopwatch)\n","reload(plib)\n","\n","STATISTICS = len(pd.read_hdf(\n","    hdf_folder+file_name, key=f'main', columns=['charge']))\n","chunksize = round((STATISTICS/worker_number))+1\n","\n","meta={\n","    'hit_detector': bool, \n","    'distances_f_raw': FLOAT_TYPE, \n","    'energies_f_raw': FLOAT_TYPE, \n","    'energies_i_raw': FLOAT_TYPE, \n","    'point1x_raw': FLOAT_TYPE, \n","    'point1y_raw': FLOAT_TYPE, \n","    'point1z_raw': FLOAT_TYPE, \n","    'point2x_raw': FLOAT_TYPE,\n","    'point2y_raw': FLOAT_TYPE,\n","    'point2z_raw': FLOAT_TYPE\n","}\n","\n","t1.task('dask tasks', True)\n","''' \n","future = client.submit(func, big_data)    # bad\n","\n","    big_future = client.scatter(big_data)     # good\n","    future = client.submit(func, big_future)  # good\n","    # own approach\n","    ddf = client.scatter(ddf)\n","    dfb = ddf.result().to_bag()\n","    # dfb = client.map(proper.pp_propagate, db.from_delayed(dfb) ) #27s\n","    # dfb = client.map(proper.pp_propagate, dfb) #27s\n","'''\n","with performance_report(filename=\"dask-report.html\"):\n","    ddf = dd.read_hdf(hdf_folder+file_name, key='main',\n","                    columns=['energy', 'theta', 'phi', 'charge'], chunksize=chunksize)\n","    dfb = ddf.to_bag()\n","\n","    dfb = dfb.map(proper.pp_propagate) #27s\n","    ddfr = dfb.to_dataframe(meta=meta)\n","    # ddfr.to_hdf(hdf_folder+'results_raw_'+file_name, key=f'main', format='table')\n","    results = client.compute(ddfr, pure=False).result()\n","\n","t1.stop(silent)\n","# %\n","t2 = stopwatch.stopwatch(title='processing of results')\n","t2.task('nachbereitung')\n","######################################################################\n","######################################################################\n","\n","\n","hit_detector = np.array(results['hit_detector'], dtype=bool)\n","distances_f_raw = np.array(results['distances_f_raw'], dtype=FLOAT_TYPE)\n","energies_f_raw = np.array(results['energies_f_raw'], dtype=FLOAT_TYPE)\n","energies_i_raw = np.array(results['energies_i_raw'], dtype=FLOAT_TYPE)\n","point1x_raw = np.array(results['point1x_raw'], dtype=FLOAT_TYPE)\n","point1y_raw = np.array(results['point1y_raw'], dtype=FLOAT_TYPE)\n","point1z_raw = np.array(results['point1z_raw'], dtype=FLOAT_TYPE)\n","point2x_raw = np.array(results['point2x_raw'], dtype=FLOAT_TYPE)\n","point2y_raw = np.array(results['point2y_raw'], dtype=FLOAT_TYPE)\n","point2z_raw = np.array(results['point2z_raw'], dtype=FLOAT_TYPE)\n","\n","counter = int(sum(hit_detector))  #len von allen die True sind\n","energies_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","energies_i = np.zeros(counter, dtype=FLOAT_TYPE)\n","distances_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","start_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","end_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","start_end_points = np.zeros(shape=(counter*2, 3), dtype=FLOAT_TYPE)\n","\n","t2.task('1')\n","i2 = 0\n","for i in range(STATISTICS):\n","    if hit_detector[i] == True:\n","        energies_f[i2] = energies_f_raw[i]\n","        energies_i[i2] = energies_i_raw[i]\n","        distances_f[i2] = distances_f_raw[i]\n","\n","        start_points[i2] = np.array([point1x_raw[i], point1y_raw[i], point1z_raw[i]])\n","        end_points[i2] = np.array([point2x_raw[i], point2y_raw[i], point2z_raw[i]])\n","\n","        start_end_points[i2*2] = start_points[i2]\n","        start_end_points[i2*2+1] = end_points[i2]\n","        i2 += 1\n","\n","t2.task('2')\n","df = pd.DataFrame()\n","df['energies_f'] = energies_f\n","df['energies_i'] = energies_i\n","df['distances'] = distances_f\n","df['point1x'] = start_points[:, 0]\n","df['point1y'] = start_points[:, 1]\n","df['point1z'] = start_points[:, 2]\n","df['point2x'] = end_points[:, 0]\n","df['point2y'] = end_points[:, 1]\n","df['point2z'] = end_points[:, 2]\n","\n","t2.task('3')\n","t2.task('write to HDF file')\n","file_name_results = f'results_{pp_config}_{file_name}'\n","df.to_hdf(hdf_folder+file_name_results, key=f'main', format='table')\n","counter_u = ufloat(counter, 1/np.sqrt(counter))\n","t2.task('4')\n","s1 = f'{counter_u:.1f} of {STATISTICS:.0e} ({counter_u/STATISTICS*100:.4}%) detector hits'\n","# s1 = f'{counter} of {STATISTICS:.0e} %) detector hits'\n","s2 = f'min(E_i) at detector = {min(energies_i)/1000:.1f} GeV'\n","print(f'{s1} | {s2}')\n","\n","t2.stop(silent)"],"outputs":[{"output_type":"stream","name":"stdout","text":["EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf | worker_number = 23\n","PROPOSAL config = sandstein_det_genauer_Wasser.json | ppconfig = v0.0008_Moliere\n","dask tasks took  4993.3 s\n","769205.0+/-0.0 of 1e+07 (7.692+/-0.000%) detector hits | min(E_i) at detector = 885.4 GeV\n"]}],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["# print(os.getcwd())\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import os, sys\n","from uncertainties import ufloat\n","# from numba import jit, njit, vectorize, prange\n","from importlib import reload\n","import py_library.my_plots_library as plib\n","import py_library.stopwatch as stopwatch\n","import py_library.simulate_lib as slib\n","import proposal as pp\n","from distributed import Client\n","from dask.distributed import performance_report\n","import dask.dataframe as dd\n","import dask.bag as db\n","\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.rcParams['font.size'] = 12\n","plt.rcParams['lines.linewidth'] = 2\n","plt.rcParams['axes.labelsize'] = 14\n","plt.rcParams.update({'figure.dpi':70})\n","# os.chdir(os.path.dirname(__file__))  # wichtig wenn nicht über ipython ausgeführt\n","client = Client(\"localhost:8786\") # phobos\n","FLOAT_TYPE = np.float64\n","{\n","'''\n","1e7\n","workers:\n","2400 KilledWorker: ('finalize-6d57127f026613e3fce3aa1731d26349', <WorkerState 'tcp://127.0.0.1:43417', status: closed, memory: 0, processing: 1>) \n","240 \n","24 2 worker sind abgeschmiert aber es lief durch \n","'''\n","}\n","show_plots = True\n","print_results = False\n","silent = True\n","# hdf_folder = 'data_hdf/'\n","hdf_folder = '/scratch/mschoenfeld/data_hdf/'\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e7_min2e2_max2e5.hdf\"\n","\n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min4e2_max2e5.hdf\"\n","\n","file_name = \"EcoMug_gaisser_30deg_3e7_min5e2_max2e5.hdf\" # 1517.6 s\n","file_name = \"EcoMug_gaisser_30deg_1e7_min5e2_max2e5.hdf\" \n","\n","file_name = \"EcoMug_gaisser_30deg_1e6_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e5_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e4_min6e2_max2e5.hdf\"\n","file_name = \"EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf\"\n","vcut = ''\n","multiple_scattering = 'HighlandIntegral'\n","multiple_scattering = 'Moliere'\n","vcut = 1\n","vcut = 0.01\n","vcut = 0.0001\n","vcut = 0.0008\n","N_tasks = 230\n","print(f'{file_name} | N_tasks = {N_tasks}')\n","\n","# %\n","######################################################################\n","######################################################################\n","t1 = stopwatch.stopwatch(\n","    title='full proposal init and simulation parallized with dask',\n","    time_unit='s')\n","t1.task('initialize proposal, making interpol tables')\n","\n","import d_pp_lib as proper\n","client.upload_file('d_pp_lib.py')\n","reload(proper)\n","pp_config = f'v{vcut}_{multiple_scattering}'\n","print(f'PROPOSAL config = {proper.config} | ppconfig = {pp_config}')\n","reload(stopwatch)\n","reload(plib)\n","\n","STATISTICS = len(pd.read_hdf(\n","    hdf_folder+file_name, key=f'main', columns=['charge']))\n","chunksize = round((STATISTICS/N_tasks))+1\n","\n","meta={\n","    'hit_detector': bool, \n","    'distances_f_raw': FLOAT_TYPE, \n","    'energies_f_raw': FLOAT_TYPE, \n","    'energies_i_raw': FLOAT_TYPE, \n","    'point1x_raw': FLOAT_TYPE, \n","    'point1y_raw': FLOAT_TYPE, \n","    'point1z_raw': FLOAT_TYPE, \n","    'point2x_raw': FLOAT_TYPE,\n","    'point2y_raw': FLOAT_TYPE,\n","    'point2z_raw': FLOAT_TYPE\n","}\n","\n","t1.task('dask tasks', True)\n","''' \n","future = client.submit(func, big_data)    # bad\n","\n","    big_future = client.scatter(big_data)     # good\n","    future = client.submit(func, big_future)  # good\n","    # own approach\n","    ddf = client.scatter(ddf)\n","    dfb = ddf.result().to_bag()\n","    # dfb = client.map(proper.pp_propagate, db.from_delayed(dfb) ) #27s\n","    # dfb = client.map(proper.pp_propagate, dfb) #27s\n","'''\n","with performance_report(filename=\"dask-report.html\"):\n","    ddf = dd.read_hdf(hdf_folder+file_name, key='main',\n","                    columns=['energy', 'theta', 'phi', 'charge'], chunksize=chunksize)\n","    dfb = ddf.to_bag()\n","\n","    dfb = dfb.map(proper.pp_propagate) #27s\n","    ddfr = dfb.to_dataframe(meta=meta)\n","    # ddfr.to_hdf(hdf_folder+'results_raw_'+file_name, key=f'main', format='table')\n","    results = client.compute(ddfr, pure=False).result()\n","\n","t1.stop(silent)\n","# %\n","t2 = stopwatch.stopwatch(title='processing of results')\n","t2.task('nachbereitung')\n","######################################################################\n","######################################################################\n","\n","\n","hit_detector = np.array(results['hit_detector'], dtype=bool)\n","distances_f_raw = np.array(results['distances_f_raw'], dtype=FLOAT_TYPE)\n","energies_f_raw = np.array(results['energies_f_raw'], dtype=FLOAT_TYPE)\n","energies_i_raw = np.array(results['energies_i_raw'], dtype=FLOAT_TYPE)\n","point1x_raw = np.array(results['point1x_raw'], dtype=FLOAT_TYPE)\n","point1y_raw = np.array(results['point1y_raw'], dtype=FLOAT_TYPE)\n","point1z_raw = np.array(results['point1z_raw'], dtype=FLOAT_TYPE)\n","point2x_raw = np.array(results['point2x_raw'], dtype=FLOAT_TYPE)\n","point2y_raw = np.array(results['point2y_raw'], dtype=FLOAT_TYPE)\n","point2z_raw = np.array(results['point2z_raw'], dtype=FLOAT_TYPE)\n","\n","counter = int(sum(hit_detector))  #len von allen die True sind\n","energies_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","energies_i = np.zeros(counter, dtype=FLOAT_TYPE)\n","distances_f = np.zeros(counter, dtype=FLOAT_TYPE)\n","start_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","end_points = np.zeros(shape=(counter, 3), dtype=FLOAT_TYPE)\n","start_end_points = np.zeros(shape=(counter*2, 3), dtype=FLOAT_TYPE)\n","\n","t2.task('1')\n","i2 = 0\n","for i in range(STATISTICS):\n","    if hit_detector[i] == True:\n","        energies_f[i2] = energies_f_raw[i]\n","        energies_i[i2] = energies_i_raw[i]\n","        distances_f[i2] = distances_f_raw[i]\n","\n","        start_points[i2] = np.array([point1x_raw[i], point1y_raw[i], point1z_raw[i]])\n","        end_points[i2] = np.array([point2x_raw[i], point2y_raw[i], point2z_raw[i]])\n","\n","        start_end_points[i2*2] = start_points[i2]\n","        start_end_points[i2*2+1] = end_points[i2]\n","        i2 += 1\n","\n","t2.task('2')\n","df = pd.DataFrame()\n","df['energies_f'] = energies_f\n","df['energies_i'] = energies_i\n","df['distances'] = distances_f\n","df['point1x'] = start_points[:, 0]\n","df['point1y'] = start_points[:, 1]\n","df['point1z'] = start_points[:, 2]\n","df['point2x'] = end_points[:, 0]\n","df['point2y'] = end_points[:, 1]\n","df['point2z'] = end_points[:, 2]\n","\n","t2.task('3')\n","t2.task('write to HDF file')\n","file_name_results = f'results_{pp_config}_{file_name}'\n","df.to_hdf(hdf_folder+file_name_results, key=f'main', format='table')\n","counter_u = ufloat(counter, 1/np.sqrt(counter))\n","t2.task('4')\n","s1 = f'{counter_u:.1f} of {STATISTICS:.0e} ({counter_u/STATISTICS*100:.4}%) detector hits'\n","# s1 = f'{counter} of {STATISTICS:.0e} %) detector hits'\n","s2 = f'min(E_i) at detector = {min(energies_i)/1000:.1f} GeV'\n","print(f'{s1} | {s2}')\n","\n","t2.stop(silent)"],"outputs":[{"output_type":"stream","name":"stdout","text":["EcoMug_gaisser_30deg_1e7_min6e2_max2e5.hdf | N_tasks = 230\n","PROPOSAL config = sandstein_det_genauer_Wasser.json | ppconfig = v0.0008_Moliere\n","dask tasks took  4962.3 s\n","769323.0+/-0.0 of 1e+07 (7.693+/-0.000%) detector hits | min(E_i) at detector = 895.5 GeV\n"]}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}